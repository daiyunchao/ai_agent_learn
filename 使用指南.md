# 本地DeepSeek模型调用指南

## 快速开始

### 1. 准备工作

确保您的本地DeepSeek模型服务已经启动，并且在以下地址可访问：
```
http://localhost:8000/v1
```

### 2. 配置模型参数

编辑 `src/config.ts` 文件，或者设置环境变量：

```bash
# 设置环境变量（可选）
export DEEPSEEK_BASE_URL="http://localhost:8000/v1"
export DEEPSEEK_API_KEY="your-api-key-here"  # 如果需要的话
export DEEPSEEK_MODEL="deepseek-chat"
```

### 3. 运行示例

```bash
# 开发模式运行（推荐）
npm run dev

# 或者编译后运行
npm run build
npm start
```

## 代码示例

### 基础HTTP调用

```typescript
import { config } from "./config";

async function callDeepSeek(prompt: string) {
    const response = await fetch(`${config.DEEPSEEK_BASE_URL}/chat/completions`, {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${config.DEEPSEEK_API_KEY}`,
        },
        body: JSON.stringify({
            model: config.DEEPSEEK_MODEL,
            messages: [{ role: "user", content: prompt }],
            temperature: 0.7,
            max_tokens: 1000,
        }),
    });
    
    const data = await response.json();
    return data.choices[0].message.content;
}
```

### LangChain集成

#### 正确的方式：使用ChatOpenAI

```typescript
import { ChatOpenAI } from "@langchain/openai";
import { ChatPromptTemplate } from "@langchain/core/prompts";

// 正确配置本地DeepSeek模型
const model = new ChatOpenAI({
    openAIApiKey: "your-api-key", // 本地可以是假的
    modelName: "deepseek-chat",
    temperature: 0.7,
    configuration: {
        baseURL: "http://localhost:8000/v1"
    }
});

// 使用现代LCEL语法
const prompt = ChatPromptTemplate.fromTemplate("回答问题: {question}");
const chain = prompt.pipe(model);

const result = await chain.invoke({ question: "什么是人工智能？" });
console.log(result.content);
```

#### 传统方式：使用LLMChain

```typescript
import { createQAChain } from "./langchain-deepseek";

async function askQuestion() {
    const qaChain = await createQAChain();
    const result = await qaChain.call({
        context: "人工智能是计算机科学的一个分支...",
        question: "什么是人工智能？"
    });
    console.log(result.text);
}
```

#### 现代方式：使用LCEL多步骤链

```typescript
import { createMultiStepChain } from "./modern-langchain-example";

async function complexProcessing() {
    const chain = await createMultiStepChain();
    const result = await chain.invoke({
        question: "如何学习TypeScript？"
    });
    console.log(result);
}
```

## 故障排除

### 常见问题

1. **连接失败**
   - 检查DeepSeek服务是否正在运行
   - 验证URL和端口是否正确
   - 确认防火墙设置

2. **API密钥错误**
   - 如果本地模型不需要密钥，可以使用默认值
   - 检查密钥配置是否正确

3. **模型名称不匹配**
   - 确认您的本地模型名称
   - 更新config.ts中的DEEPSEEK_MODEL配置

### 调试模式

在代码中添加日志来调试：

```typescript
console.log("模型URL:", config.DEEPSEEK_BASE_URL);
console.log("模型名称:", config.DEEPSEEK_MODEL);
```

## 扩展功能

### 添加新的链类型

```typescript
export async function createCustomChain() {
    const llm = new DeepSeekLLM();
    const template = `自定义提示模板: {input}`;
    const prompt = PromptTemplate.fromTemplate(template);
    return new LLMChain({ llm, prompt });
}
```

### 集成向量数据库

可以集成Chroma、Pinecone等向量数据库来实现RAG功能。

### 添加对话记忆

使用LangChain的记忆组件来保持对话上下文。

## 性能优化

1. **调整温度参数**: 根据需要调整创造性 (0.1-1.0)
2. **设置最大令牌数**: 控制响应长度
3. **添加请求缓存**: 避免重复计算
4. **并发控制**: 限制同时进行的请求数量

## 下一步

- 探索更多LangChain工具和代理
- 实现自定义工具和插件
- 集成外部API和数据源
- 构建完整的对话系统 